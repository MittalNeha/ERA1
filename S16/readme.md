# Task
1. Pick the "en-fr" dataset from opus_books <br>
2. Remove all English sentences with more than 150 "tokens" <br>
3. Remove all french sentences where len(fench_sentences) > len(english_sentrnce) + 10<br>
4. Train your own transformer (E-D) (do anything you want, use PyTorch, OCP, PS, AMP, etc), but get your loss under 1.8 <br>

## Experiments done
